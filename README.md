# Model Eval results

### openllm Benchmark results

| Model | Details | Average | arc | gsm8k | hellaswag | mmlu | truthfulqa | winogrande |
|---|---|---|---|---|---|---|---|---|
| [Arithmo-Wizard-2-7B](https://huggingface.co/saucam/Arithmo-Wizard-2-7B) | [complete result](saucam/Arithmo-Wizard-2-7B/README.md) | 65.22 | 62.88 | 61.26 | 83.15 | 60.61 | 45.9 | 77.51 |
| [Nereus-7B](https://huggingface.co/saucam/Nereus-7B) | [complete result](saucam/Nereus-7B/README.md) | 63.82 | 62.54 | 46.25 | 83.23 | 59.6 | 54.32 | 76.95 |
| [Orpomis-Prime-7B-dare](https://huggingface.co/saucam/Orpomis-Prime-7B-dare) | [complete result](saucam/Orpomis-Prime-7B-dare/README.md) | 67.37 | 64.68 | 59.74 | 85.12 | 62.21 | 53.72 | 78.77 |
| [Orpomis-Prime-7B-it](https://huggingface.co/saucam/Orpomis-Prime-7B-it) | [complete result](saucam/Orpomis-Prime-7B-it/README.md) | 55.67 | 61.26 | 24.34 | 79.61 | 51.55 | 43.68 | 73.56 |
| [Orpomis-Prime-7B](https://huggingface.co/saucam/Orpomis-Prime-7B) | [complete result](saucam/Orpomis-Prime-7B/README.md) | 55.27 | 60.67 | 24.41 | 79.12 | 52.43 | 41.02 | 73.95 |
| [mistral-orpo-beta-NeuralBeagle14-7B-dare-ties](https://huggingface.co/saucam/mistral-orpo-beta-NeuralBeagle14-7B-dare-ties) | [complete result](saucam/mistral-orpo-beta-NeuralBeagle14-7B-dare-ties/README.md) | 70.06 | 67.32 | 61.79 | 85.89 |  | 54.17 | 81.14 |


### nous Benchmark results

| Model | Details | Average | agieval | bigbench | gpt4all | truthfulqa |
|---|---|---|---|---|---|---|
| [Arithmo-Wizard-2-7B](https://huggingface.co/saucam/Arithmo-Wizard-2-7B) | [complete result](saucam/Arithmo-Wizard-2-7B/README.md) | 46.28 | 31.58 | 37.44 | 70.2 | 45.91 |
| [Nereus-7B](https://huggingface.co/saucam/Nereus-7B) | [complete result](saucam/Nereus-7B/README.md) | 52.12 | 42.8 | 39.17 | 72.21 | 54.32 |
| [Orpomis-Prime-7B-dare](https://huggingface.co/saucam/Orpomis-Prime-7B-dare) | [complete result](saucam/Orpomis-Prime-7B-dare/README.md) | 52.42 | 42.71 | 39.82 | 73.42 | 53.72 |
| [Orpomis-Prime-7B-it](https://huggingface.co/saucam/Orpomis-Prime-7B-it) | [complete result](saucam/Orpomis-Prime-7B-it/README.md) | 47.98 | 37.23 | 38.72 | 72.28 | 43.68 |
| [Orpomis-Prime-7B](https://huggingface.co/saucam/Orpomis-Prime-7B) | [complete result](saucam/Orpomis-Prime-7B/README.md) | 46.78 | 36.4 | 37.5 | 72.18 | 41.02 |
| [bert-tiny-finetuned-sms-spam-detection](https://huggingface.co/mrm8488/bert-tiny-finetuned-sms-spam-detection) | [complete result](mrm8488/bert-tiny-finetuned-sms-spam-detection/README.md) | 33.97 | 22.95 | 28.75 | 36.07 | 48.09 |
