# Model Eval results

## mistral-orpo-beta-NeuralBeagle14-7B-dare-ties results

|Benchmark|                                                           Model                                                            |winogrande| arc |gsm8k|truthfulqa|hellaswag|Average|
|---------|----------------------------------------------------------------------------------------------------------------------------|---------:|----:|----:|---------:|--------:|------:|
|openllm  |[mistral-orpo-beta-NeuralBeagle14-7B-dare-ties](https://huggingface.co/saucam/mistral-orpo-beta-NeuralBeagle14-7B-dare-ties)|     81.14|67.32|61.79|     54.17|    85.89|  70.06|



For detailed results see [here](saucam/mistral-orpo-beta-NeuralBeagle14-7B-dare-ties/README.md)

## Orpomis-Prime-7B-dare results

|Benchmark|                                   Model                                    |agieval|gpt4all|bigbench|truthfulqa|Average|
|---------|----------------------------------------------------------------------------|------:|------:|-------:|---------:|------:|
|nous     |[Orpomis-Prime-7B-dare](https://huggingface.co/saucam/Orpomis-Prime-7B-dare)|  42.71|  73.42|   39.82|     53.72|  52.42|


|Benchmark|                                   Model                                    |winogrande| arc |gsm8k|mmlu |truthfulqa|hellaswag|Average|
|---------|----------------------------------------------------------------------------|---------:|----:|----:|----:|---------:|--------:|------:|
|openllm  |[Orpomis-Prime-7B-dare](https://huggingface.co/saucam/Orpomis-Prime-7B-dare)|     78.77|64.68|59.74|62.21|     53.72|    85.12|  67.37|



For detailed results see [here](saucam/Orpomis-Prime-7B-dare/README.md)

## Nereus-7B results

|Benchmark|                       Model                        |agieval|gpt4all|bigbench|truthfulqa|Average|
|---------|----------------------------------------------------|------:|------:|-------:|---------:|------:|
|nous     |[Nereus-7B](https://huggingface.co/saucam/Nereus-7B)|   42.8|  72.21|   39.17|     54.32|  52.12|


|Benchmark|                       Model                        |winogrande| arc |gsm8k|mmlu|truthfulqa|hellaswag|Average|
|---------|----------------------------------------------------|---------:|----:|----:|---:|---------:|--------:|------:|
|openllm  |[Nereus-7B](https://huggingface.co/saucam/Nereus-7B)|     76.95|62.54|46.25|59.6|     54.32|    83.23|  63.82|



For detailed results see [here](saucam/Nereus-7B/README.md)

## Orpomis-Prime-7B-it results

|Benchmark|                                 Model                                  |agieval|gpt4all|bigbench|truthfulqa|Average|
|---------|------------------------------------------------------------------------|------:|------:|-------:|---------:|------:|
|nous     |[Orpomis-Prime-7B-it](https://huggingface.co/saucam/Orpomis-Prime-7B-it)|  37.23|  72.28|   38.72|     43.68|  47.98|


|Benchmark|                                 Model                                  |winogrande| arc |gsm8k|mmlu |truthfulqa|hellaswag|Average|
|---------|------------------------------------------------------------------------|---------:|----:|----:|----:|---------:|--------:|------:|
|openllm  |[Orpomis-Prime-7B-it](https://huggingface.co/saucam/Orpomis-Prime-7B-it)|     73.56|61.26|24.34|51.55|     43.68|    79.61|  55.67|



For detailed results see [here](saucam/Orpomis-Prime-7B-it/README.md)

## Orpomis-Prime-7B results

|Benchmark|                              Model                               |agieval|gpt4all|bigbench|truthfulqa|Average|
|---------|------------------------------------------------------------------|------:|------:|-------:|---------:|------:|
|nous     |[Orpomis-Prime-7B](https://huggingface.co/saucam/Orpomis-Prime-7B)|   36.4|  72.18|    37.5|     41.02|  46.78|


|Benchmark|                              Model                               |winogrande| arc |gsm8k|mmlu |truthfulqa|hellaswag|Average|
|---------|------------------------------------------------------------------|---------:|----:|----:|----:|---------:|--------:|------:|
|openllm  |[Orpomis-Prime-7B](https://huggingface.co/saucam/Orpomis-Prime-7B)|     73.95|60.67|24.41|52.43|     41.02|    79.12|  55.27|



For detailed results see [here](saucam/Orpomis-Prime-7B/README.md)

## bert-tiny-finetuned-sms-spam-detection results

|Benchmark|                                                     Model                                                     |agieval|gpt4all|bigbench|truthfulqa|Average|
|---------|---------------------------------------------------------------------------------------------------------------|------:|------:|-------:|---------:|------:|
|nous     |[bert-tiny-finetuned-sms-spam-detection](https://huggingface.co/mrm8488/bert-tiny-finetuned-sms-spam-detection)|  22.95|  36.07|   28.75|     48.09|  33.97|



For detailed results see [here](mrm8488/bert-tiny-finetuned-sms-spam-detection/README.md)

