{
  "results": {
    "arc_challenge": {
      "acc": 0.22525597269624573,
      "acc_stderr": 0.012207839995407319,
      "acc_norm": 0.26109215017064846,
      "acc_norm_stderr": 0.012835523909473862
    },
    "arc_easy": {
      "acc": 0.24915824915824916,
      "acc_stderr": 0.008875238553583175,
      "acc_norm": 0.24579124579124578,
      "acc_norm_stderr": 0.008834809366391487
    },
    "boolq": {
      "acc": 0.3764525993883792,
      "acc_stderr": 0.008473882279194591
    },
    "hellaswag": {
      "acc": 0.2584146584345748,
      "acc_stderr": 0.004368684255626191,
      "acc_norm": 0.2633937462656841,
      "acc_norm_stderr": 0.004395739495688587
    },
    "openbookqa": {
      "acc": 0.164,
      "acc_stderr": 0.016575811142446686,
      "acc_norm": 0.292,
      "acc_norm_stderr": 0.02035437548053008
    },
    "piqa": {
      "acc": 0.5119695321001088,
      "acc_stderr": 0.011662480968070049,
      "acc_norm": 0.49510337323177367,
      "acc_norm_stderr": 0.01166526473007814
    },
    "winogrande": {
      "acc": 0.49329123914759276,
      "acc_stderr": 0.014051220692330346
    }
  },
  "versions": {
    "arc_challenge": 0,
    "arc_easy": 0,
    "boolq": 1,
    "hellaswag": 0,
    "openbookqa": 0,
    "piqa": 0,
    "winogrande": 0
  },
  "config": {
    "model": "hf-causal",
    "model_args": "pretrained=mrm8488/bert-tiny-finetuned-sms-spam-detection,trust_remote_code=False",
    "num_fewshot": 0,
    "batch_size": "auto",
    "device": "cuda:0",
    "no_cache": false,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}